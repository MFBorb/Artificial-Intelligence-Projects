# -*- coding: utf-8 -*-
"""Assignment3DeepLearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rQmfvFU-V8maKPDx8NVR9arI94WdYuX7

# Import Declarations
"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension.
# %load_ext tensorboard

from datetime import datetime
from packaging import version

import tensorflow as tf
from tensorflow import keras

import tensorboard
import matplotlib.pyplot as plt

import numpy as np

"""# Main Function:"""

def main():
  print("Question 1:\n")
  question1()

  print("\nQuestion 2:\n")
  question2()

  # Question 3 was done by hand with pencil and paper. The answers
  # will be included in the report.

  return

"""# Question 1:"""

def question1():
  # Load in the data and normalize it
  # We don't actually use the test_images/labels
  (train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()
  train_images = train_images / 255

  # Network 1 - Increasing number of filters
  print("\nNetwork 1 - Increasing number of filters: ")
  networkIncreasingFilters(train_images, train_labels)

  # Network 2 - Decreasing number of filters
  print("\nNetwork 2 - Decreasing number of filters: ")
  networkDecreasingFilters(train_images, train_labels)

  # Network 3 - Hourglass shaped CNN, increase til Lth layer than reduce
  print("\nNetwork 3 - Hourglass shaped CNN")
  networkHourglassFilters(train_images, train_labels)

  return

"""Network Functions:"""

# This network has an increasing number of filters.
# The general structure is:
#   Groups of two layers:
#       First layer is a power of 2 with a 3x3 filter.
#       Second layer is halfway between the first layer and the next power of 2 with a 5x5 filter.
#   Max Pool layer on all groups except the smallest one.
def networkIncreasingFilters(train_images, train_labels):
  x_train = train_images.reshape(-1, 28, 28, 1)

  cnn_model = tf.keras.models.Sequential()

  cnn_model.add(tf.keras.layers.Conv2D(8, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(12, (5, 5), padding='same', activation='relu'))

  cnn_model.add(tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(24, (5, 5), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(48, (5, 5), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(96, (5, 5), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(192, (5, 5), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Flatten())
  cnn_model.add(tf.keras.layers.Dense(256, activation='relu'))
  cnn_model.add(tf.keras.layers.Dense(10, activation='softmax'))

  cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])
  cnn_model.build(input_shape=(1, 28, 28, 1))

  cnn_model.fit(x_train,
                train_labels,
                batch_size=256,
                epochs=10)
  return

# This network has a decreasing number of filters.
# The general structure is:
#   Groups of two layers:
#       First layer is halfway between 2 powers of 2 with a 3x3 filter.
#       Second layer is a power of 2 with a 5x5 filter.
#   Max Pool layer on all groups except the smallest one.
def networkDecreasingFilters(train_images, train_labels):
  x_train = train_images.reshape(-1, 28, 28, 1)

  cnn_model = tf.keras.models.Sequential()

  cnn_model.add(tf.keras.layers.Conv2D(192, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Conv2D(96, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Conv2D(48, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Conv2D(24, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(16, (5, 5), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Conv2D(12, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(8, (5, 5), padding='same', activation='relu'))

  cnn_model.add(tf.keras.layers.Flatten())
  cnn_model.add(tf.keras.layers.Dense(256, activation='relu'))
  cnn_model.add(tf.keras.layers.Dense(10, activation='softmax'))

  cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  cnn_model.build(input_shape=(1, 28, 28, 1))

  cnn_model.fit(x_train,
                train_labels,
                batch_size=128,
                epochs=10)
  return

# This network has an increasing number of filters until we reach the CONV
# layer with 128 filters, then we decrease the number of filters.
def networkHourglassFilters(train_images, train_labels):
  x_train = train_images.reshape(-1, 28, 28, 1)

  cnn_model = tf.keras.models.Sequential()

  cnn_model.add(tf.keras.layers.Conv2D(8, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu'))

  cnn_model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  # Stops increasing here. After this, start decreasing.
  cnn_model.add(tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Conv2D(96, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))

  cnn_model.add(tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu'))
  cnn_model.add(tf.keras.layers.Conv2D(8, (3, 3), padding='same', activation='relu'))

  cnn_model.add(tf.keras.layers.Flatten())
  cnn_model.add(tf.keras.layers.Dense(256, activation='relu'))
  cnn_model.add(tf.keras.layers.Dense(10, activation='softmax'))

  cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])
  cnn_model.build(input_shape=(1, 28, 28, 1))

  cnn_model.fit(x_train,
                train_labels,
                batch_size=64,
                epochs=10)
  return

"""# Question 2:"""

def question2():
  (train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()
  train_images = train_images / 255

  leNetImplementation(train_images, train_labels)
  print()
  feedForwardImplementation(train_images, train_labels)
  return

"""Network Functions:"""

def leNetImplementation(train_images, train_labels):
  x_train = train_images.reshape(-1, 32, 32, 3)

  leNet_model = keras.models.Sequential()

  leNet_model.add(keras.layers.Conv2D(6, (5, 5), padding='same', activation='relu'))
  leNet_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
  leNet_model.add(keras.layers.Conv2D(16, (5, 5), padding='same', activation='relu'))
  leNet_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
  leNet_model.add(keras.layers.Conv2D(120, (5, 5), padding='same', activation='relu'))
  leNet_model.add(keras.layers.Flatten())
  leNet_model.add(keras.layers.Dense(84, activation='relu'))
  leNet_model.add(keras.layers.Dense(10, activation='softmax'))

  # Default learning rate for Adam is 0.001
  tweakedAdam = keras.optimizers.Adam(learning_rate=0.001)

  leNet_model.compile(loss='sparse_categorical_crossentropy', optimizer=tweakedAdam, metrics=['accuracy'])
  leNet_model.build(input_shape=(1, 32, 32, 3))

  leNet_model.fit(x_train,
                train_labels,
                batch_size=64,
                epochs=25)

  return

def feedForwardImplementation(train_images, train_labels):
  x_train = train_images.reshape(-1, 32, 32, 3)

  feedForward_model = keras.models.Sequential()

  feedForward_model.add(keras.layers.Flatten())
  feedForward_model.add(keras.layers.Dense(6, activation='relu'))
  feedForward_model.add(keras.layers.Dense(16, activation='relu'))
  feedForward_model.add(keras.layers.Dense(120, activation='relu'))
  feedForward_model.add(keras.layers.Dense(84, activation='relu'))
  feedForward_model.add(keras.layers.Dense(10, activation='softmax'))

  # Default learning rate for Adam is 0.001
  tweakedAdam = keras.optimizers.Adam(learning_rate=0.0025)

  feedForward_model.compile(loss='sparse_categorical_crossentropy', optimizer=tweakedAdam, metrics=['accuracy'])
  feedForward_model.build(input_shape=(1, 32, 32, 3))


  feedForward_model.fit(x_train,
                train_labels,
                batch_size=64,
                epochs=25)
  return

"""# Main Function Call"""

main()

"""# Report:

**Question 1:**


*   Most of my testing was done with the Adam optimizer. This was because I didn't see the line about changing the hyperparameters including "choice of optimizer" and assumed Adam would be the best until I started typing this report. At that moment, it was too late to do throrough testing with the better optimizer (due to not enough time and Colab would disallow use of the GPU). Since most of my testing was done with Adam, I will still analyze the efficiency of changing each hyperparameter along with explaining why some optimizers didn't work well.
* While trying to maximize the Adam network, I started with changing the number of filters in the first network to determine how well they'll fit depending on the number. After this, I tested changing the batch size and learning rate with each network. Once I found the best batch size and learning rate, I changed the optimizer. Accuracies for combinations of hyperparameters are shown below:

Network 1:
>Starting at 4
>>Batch Size 64:
>>>Learning Rate 0.001: 0.9939.

>>>Learning Rate 0.002: 0.9915.

>>>Learning Rate 0.005: 0.1110.

>>Batch Size 128:
>>>Learning Rate 0.001: 0.9941.

>>>Learning Rate 0.002: 0.9918.

>>>Learning Rate 0.005: 0.1120.

>>Batch Size 256:
>>>Learning Rate 0.001: 0.9937.

>>>Learning Rate 0.002: 0.9942.

>>>Learning Rate 0.005: 0.9924.


>Starting at 8:
>>Batch Size 64:
>>>Learning Rate 0.001: 0.9948.

>>>Learning Rate 0.002: 0.1122.

>>>Learning Rate 0.005: 0.1106.

>>Batch Size 128:
>>>Learning Rate 0.001: 0.9956.

>>>Learning Rate 0.002: 0.1124.

>>>Learning Rate 0.005: 0.1118.

>>Batch Size 256:
>>>Learning Rate 0.001: 0.9959.

>>>Learning Rate 0.002: 0.1124.

>>>Learning Rate 0.005: 0.1124.

>Adam: 0.9959

>Default SGD: 0.97

>SGD w/ 0.001 Rate: 0.1124

>RMSProp: 0.9972


Network 2:
>Batch Size 64:
>>Learning Rate 0.001: 0.1124.

>>Learning Rate 0.002: 0.9911.

>>Learning Rate 0.005: 0.1118.

>Batch Size 128:
>>Learning Rate 0.001: 0.9952.

>>Learning Rate 0.002: 0.9943.

>>Learning Rate 0.005: 0.9748.

>Batch Size 256:
>>Learning Rate 0.001: 0.9944.

>>Learning Rate 0.002: 0.9949.

>>Learning Rate 0.005: 0.1124.

>Adam: 0.9952

>Default SGD: 0.1124

>SGD w/ 0.001 Rate: 0.1124

>RMSProp: 0.1124

Network 3:
>Batch Size 64:
>>Learning Rate 0.001: 0.9955

>>Learning Rate 0.002: 0.9947

>>Learning Rate 0.005: 0.1116

>Batch Size 128:
>>Learning Rate 0.001: 0.9952

>>Learning Rate 0.002: 0.9949

>>Learning Rate 0.005: 0.9897

>Batch Size 256:
>>Learning Rate 0.001: 0.9950

>>Learning Rate 0.002: 0.9939

>>Learning Rate 0.005: 0.9920

>Adam: 0.9955

>Default SGD: 0.1124

>SGD w/ 0.001 Rate: 0.1124

>RMSProp: 0.9966

* Network 1's best hyperparameters were: learning rate of 0.001, batch size of 256, and the RMSProp optimizer.
* Network 2's best hyperparameters were: learning rate of 0.001, batch size of 128, and the Adam optimizer.
* Network 3's best hyperparameters were: learning rate of 0.001, batch size of 64, and the RMSProp optimizer.

* As explained above, I tested the batch size and learning rate with the Adam optimizer. Only after all of that was done was when I discovered that I needed to change the optimizer too, not allowing for thorough testing of other optimizers. However, the RMSProp optimizer with the values found through the Adam optimization did better than the Adam optimization except for Network 2. The accuracy was already high, so any improvement was substantial.
* Something else to note was that if a combination of hyperparameters did poorly, it often converged to 0.1124. I'm unsure as to why this behavior happens, but it is observable in the accuracies above.
* My guess as to why the 0.001 learning rate did well is because it allows for quick approach of the global maximum while still being low enough to converge without bouncing around the global maximum. A learning rate of 0.002 still did well, but it didn't work well on some cases (such as Network 1, starting at 8, batch size 64). It approaches the global maximum quickly but struggles to converge.
* The networks performed well. The large amount of parameters allows for a high fit with the dataset. Additionally, I included both filters of 3x3 size and 5x5 size to be able to detect small and large details in the images that were important to detect the number.
* Network 1's batch size helps quickly reach convergence due to the simplicity of its architecture. The large batch size helps get rid of any noise in the pictures, which is important as the early parameters are the basis of the architecture. A lot of noise in the beginning parameters will lead to many incorrect predictions.
* Network 2's batch size is the opposite of network 1's. Since we decrease the number of filters, we deal with some noise as the later filters will be able to differentiate between high-level details after the beginning filters differentiate between low-level details
* Network 3's batch size is small due to the unique architexture of the network. The hourglass shape tries to combine the first two architectures and focus on the high-level abstractions. The early filters pick up on high-level abstractions that are quickly visible. The later filters serve as a way to pick up abstractions that are not as apparent until we analyze the data. The smaller data size is needed to make sure our model is able to capture the high-level abstractions correctly. More updates means more chances to fit to the data better. Since both ends of the model serve to capture high-level abstractions, noise will not be a problem like it was in the first network. High-level abstractions will not care about noise.

**Question 2:**

* To test the learning rate, I used a constant batch size of 128 across 4 different learning rates: 0.0005, 0.001, 0.002, 0.005. Increasing the learning rate generally made the accuracy rise quickly, but then would bounce around a range of values that was wider if the learning rate was bigger. 0.0005 would be between 0.94 to 0.95 while 0.005 would bounce between 0.85 to 0.89. As for the effect it had the the final accuracy, as the learning rate increases, the model becomes better fit until it reaches a certain learning rate and it starts decreasing from there. For example, the model became better fit between 0.0005 and 0.001, but then became worse past 0.001. The best learning rate was 0.001.

* To test the batch size, I used a constant learning rate of 0.001 across 4 different batch sizes: 64, 128, 256, 512. When testing, batch size became a trade-off between speed and accuracy. A higher batch size meant it wouldn't take as long but the model wouldn't fit the training data as well. However, depending on the model, this trade-off might be negligible. A batch size of 128 took much shorter to train than a batch size of 64, but their accuracies had a difference 0.0001 (0.9712 for 128 and 0.9713 for 64).

* The hyperparameters I tried changing were both learning rate and batch size. I tried all combinations of 0.0005, 0.001, 0.002, 0.005 for learning rate and 64, 128, and 256 for batch size. My best performance was a 0.9720 accuracy with a learning rate of 0.001 and batch size of 64.

*Performance of the Feed-Forward NN*

* Its performance was very poor. I tried many different hyperparameters, including ones I did not try for the LeNet implementation, yet I could only get between 0.1 and 0.2 accuracy. There was also a weird tendency to jump from 0.1 accuracy to 0.2 accuracy when changing hyperparameters, but they would always go back to near 0.11 accuracy if the model was trained again. The average accuracy for this model was about 0.11.

* This feed-forward network had 31604 parameters compared to LeNet's 697036 parameters. Simply put, no, these parameters are not worth it. LeNet had a much greater ability to fit the data than this feed-forward network (0.9720 accuracy vs 0.11 accuracy) with a small trade-off of 1 minute and 30 seconds of extra time. This incredible difference in accuracy makes LeNet much more desirable as a model even with the time trade-off.

**Question 3:**
* The dimensions of the input are 6x6x1. The dimensions of the kernel are 3x3x1. There are 3x3x1 + 1 = 10 parameters in the kernel.

* The output activation map is shown below:
![Screenshot (184).png](data:image/png;base64,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)

* To derive this output activation map, I started by applying the 3x3 filter defined in the problem over the input matrix with a stride of (1, 1). For each 3x3 snippet of the input matrix, I would multiply the elements in the input by the elements in the filter that overlayed each other and summed the products together. For example, with a 2x2 snippet and 2x2 filter of [[a, b], [c, d]] and [[e, f], [g, h]], the element in the output activation map would be ae + bf + cg + dh. I repeated this until I reached the end of the input matrix.

* The max pool output is shown below:
![Screenshot (183).png](data:image/png;base64,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)

* To derive this matrix, I applied a 2x2 filter with a stride of (2, 2) onto the activation map. For each snippet of the activation map, I took the maximum value from that snippet and that became the element in the output.
"""